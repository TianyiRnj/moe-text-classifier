# moe-text-classifier
A high‑performance Mixture‑of‑Experts text classification framework built on DeepSeek‑MoE‑16B, featuring DeepSpeed‑accelerated multi‑GPU training, selective layer freezing, activation checkpointing, and mixed‑precision support for classifying short psychological‑health statements.
